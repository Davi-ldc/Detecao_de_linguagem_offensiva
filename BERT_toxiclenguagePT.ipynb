{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8NNNOX4XEIP"
   },
   "source": [
    "Esse notebook tem como objetivo a identifica\u00e7\u00e3o de discurso de odio com a ultiliza\u00e7\u00e3o do chatgpt + Alice para gerar o dataset e BERT com LSTM para a previs\u00e3o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1B_GsKqGJQNR"
   },
   "source": [
    "# Importes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dR8T4VyIFYye",
    "outputId": "ec18a99f-20b0-4199-db91-706c70fa25d7"
   },
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install --upgrade huggingface_hub\n",
    "!pip install transformers\n",
    "!pip install toxigen\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KtuOLitqFdIT"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332,
     "referenced_widgets": [
      "efadc5051de448e091cd76755371cc9f",
      "a220fe561e054614a819821e35ad3d3d",
      "3f49fcb4d79c4a2599573d64b2466140",
      "0a8b6d3a3b9c48a5878b58c2f3933f69",
      "5c2f22e1d46c4c16a0c25ff0d6c726b4",
      "bc83b01ddd144e38bff29ae0920cc98a",
      "effe990ecf06444ba81f873b290ddc37",
      "be5b60b77b8d45e79651b365a69499be",
      "273c382d7a88488197e0565aca12f90e",
      "5aa07aa277b14a7da279aa0e820ee83f",
      "3ff8747619a040e8ae5bcbab7b6adab4",
      "d8d1be78d2274c6d8b53c2382f953bd5",
      "f2f2a37e44194ee9ab4cad389a29e3a1",
      "672e003592a843779aa02ae363c361e0",
      "e9059b7cfe834b5c82d2a168d406f832",
      "45d9e8546b964905bdcec026f15aa2b7",
      "3f3e976f3ba04f91a61459e91d9ff5b6"
     ]
    },
    "id": "YaV9GtxjFqxO",
    "outputId": "599c5a8e-73bd-41a3-8174-83803f8671dd"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kS01J2s1wLkv"
   },
   "source": [
    "# caregando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "id": "LpX6o6liffhr",
    "outputId": "1bc07b7e-1098-4fae-885f-f3fba58c90cf"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"ruanchaves/hatebr\", use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M1qpONrye1zF"
   },
   "outputs": [],
   "source": [
    "data1 = pd.DataFrame(dataset[\"train\"])\n",
    "data2 = pd.DataFrame(dataset[\"test\"])\n",
    "data = pd.concat([data1, data2])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ShCNrm5rDXM"
   },
   "outputs": [],
   "source": [
    "data = data.drop(['offensiveness_levels', 'antisemitism', 'apology_for_the_dictatorship', 'fatphobia', 'homophobia', 'partyism', 'racism', 'religious_intolerance', 'sexism', 'xenophobia', 'offensive_&_non-hate_speech', 'non-offensive', 'specialist_1_hate_speech', 'specialist_2_hate_speech', 'specialist_3_hate_speech'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0eVSNNVerShA"
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fRYXsKGJdyXM"
   },
   "source": [
    "# frases a m\u00e3o:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AcHDs5cyd0SK"
   },
   "outputs": [],
   "source": [
    "a = {\n",
    "    'querido filho Fiquei sabendo que voc\u00ea ter\u00e1 seu primeiro debate fudido na pr\u00f3xima semana':0,\n",
    "    'por mim agente acabava logo com essa modinha de ser gay e voltava tudo ao normal':1,\n",
    "    'os gays sofreram muito preconceito ao longo da hist\u00f3ria':0,\n",
    "    'a xenof\u00f3bia deve ser evitada':0,\n",
    "    \n",
    "    'Eu j\u00e1 conhe\u00e7o bem suas ideias antifeministas e sei que a feminista que debater\u00e1 com voc\u00ea \u00e9 extremista':0,\n",
    "    'os comunistas s\u00e3o pessoas como nos':0, \n",
    "    'aquele cara \u00e9 um babaca':1,\n",
    "    'quem n\u00e3o deve n\u00e3o teme':0,\n",
    "    'podemos concluir que a terra \u00e9 redonda':0, \n",
    "    'todo ind\u00edgena \u00e9 corrupto':1, \n",
    "    'hoje foi ha loja de Dona maria comprar p\u00e3o quando derepente':0,\n",
    "    \"eu quero matar os indigenas\":1,\n",
    "    \"os deficientes n\u00e3o fazem porra nenhuma e agente ainda sim fica sustentando eles\":1,\n",
    "    \"Os doentes mentais s\u00e3o inuteis\":1,  \n",
    "    \"Os mul\u00e7umanos s\u00e3o tudo terrorista\":1,\n",
    "    \"preto \u00e9 tudo pregui\u00e7oso\":1,\n",
    "    \"As mulheres que usam roupas curtas t\u00e3o pedindo para serem estupradas\":1,\n",
    "    \"Os ind\u00edgenas s\u00e3o atrasados e precisam se integrar \u00e0 civiliza\u00e7\u00e3o\":1,\n",
    "    \"Os Nordestinos s\u00e3o fracassados e n\u00e3o trabalham o suficiente\":1,\n",
    "    \"se a pessoa \u00e9 pobre problema dela\":1,\n",
    "    \"Os gays s\u00e3o uma amea\u00e7a a fam\u00edlia\":1,\n",
    "    \"Vamos acabar com esses comunistas\":1,\n",
    "    \"todo politico \u00e9 corrupto\":1,\n",
    "    \"eu n\u00e3o quero meu filho perto desses animais\":1,\n",
    "    \"homossexualidade \u00e9 uma doen\u00e7a\":1,\n",
    "    \"gays s\u00e3o doentes\":1, \n",
    "    \"Todas os trans deveriam ser exterminados\":1,\n",
    "    \"Mulheres s\u00e3o inferiores aos homens\":1,\n",
    "    \"Ra\u00e7a branca \u00e9 superior\":1,\n",
    "    \"Os esquerdistas devem ser eliminados\":1,\n",
    "    \"Negros n\u00e3o s\u00e3o humanos\":1,\n",
    "    \"Todo o judeu deve ser enviado pro campo de concentra\u00e7\u00e3o\":1,\n",
    "    \"As mulheres n\u00e3o devem ter direito ao voto\":1,\n",
    "    \"Os refugiados s\u00e3o uma praga e devem ser expulsos do pa\u00eds\":1,\n",
    "    \"Todo nordestino \u00e9 folgado\":1,\n",
    "    \"Os ateus devem ser punidos com a morte por negar a exist\u00eancia de Deus\":1,\n",
    "    'Resumindo a tortura deve ser considerada pelo estado para obter informa\u00e7\u00f5es':1,\n",
    "    'acaba que na pr\u00e1tica os nosso maior problema s\u00e3o os gays':1,\n",
    "    'os gays merecem respeito':0,\n",
    "    \"Os \u00edndios merecem ser exterminados\":1,\n",
    "    \"As mulheres que abortam devem ser punidas com a morte\":1,\n",
    "    \"OS gays s\u00e3o ped\u00f3filos\":1,\n",
    "    \"Todos esses pretos deviam voltar pra a \u00c1frica\":1,\n",
    "    \"Os homossexuais s\u00e3o doentes mentais e devem ser curados \u00e0 for\u00e7a\":1,\n",
    "    \"As mulheres s\u00e3o muito burras pra trabalhar\":1,\n",
    "    \"todo favelado \u00e9 ladr\u00e3o\":1,\n",
    "    \"Os homens s\u00e3o superiores \u00e0s mulheres\":1,\n",
    "    \"Todo gordo \u00e9 nojento\":1,\n",
    "    \"Negros devem ser separados dos brancos\":1,\n",
    "    \"Todos os LGBT s\u00e3o doentes mentais e devem ser internados em hospitais psiqui\u00e1tricos\":1,\n",
    "    \"Judeus s\u00e3o uma praga\":1,\n",
    "    \"Deficientes n\u00e3o servem pra nada\":1,\n",
    "    \"Os \u00edndios s\u00e3o selvagens e devem ser civilizados\":1,\n",
    "    \"As mulheres n\u00e3o servem pra jogar futebol\":1,\n",
    "    'O problema \u00e9 que como todos os pol\u00edticos s\u00e3o ladr\u00f5es n\u00e3o podemos mais confiar no sistema eleitora Brasileiro':1,\n",
    "    \"Os ateus s\u00e3o criminosos e devem ser punidos com a morte\":1,\n",
    "    \"As mulheres s\u00e3o objetos sexuais e devem ser submissas aos homens\":1,\n",
    "    \"Os judeus s\u00e3o respons\u00e1veis por todos os males do mundo\":1,\n",
    "    \"Os negros s\u00e3o pregui\u00e7osos e n\u00e3o merecem nada\":1,\n",
    "    \"Os homens s\u00e3o superiores\":1,\n",
    "    \"Os \u00edndios n\u00e3o merecem direitos e devem ser expulsos de suas terras\":1,\n",
    "    \"Os homossexuais devem ser condenados \u00e0 morte\":1,\n",
    "    \"os ateus n\u00e3o t\u00eam nenhum valor moral\":1, \n",
    "    \"prefiro um filho morto do que um filho gay\":1, \n",
    "    \"os mexicanos s\u00e3o todos traficantes\":1, \n",
    "    \"Chines \u00e9 tudo comunista\":1, \n",
    "    \"Crist\u00e3os s\u00e3o hip\u00f3critas fudidos\":1,\n",
    "    \"os refugiados s\u00f3 servem pra roubar emprego\":1,\n",
    "    \"Os pobres s\u00e3o pregui\u00e7osas e n\u00e3o se esfor\u00e7am para melhorar suas vidas\":1,\n",
    "    \"Os \u00edndios s\u00e3o pregui\u00e7osos e vivem \u00e0s custas do governo\":1,\n",
    "    \"Os ciganos s\u00e3o ladr\u00f5es\":1,\n",
    "    \"no PT s\u00f3 tem bandido\":1,\n",
    "    \"Os africanos s\u00e3o selvagens\":1,\n",
    "    \"os autistas n\u00e3o servem pra nada\":1,\n",
    "    \"Os ateus s\u00e3o moralmente falidos e n\u00e3o t\u00eam valores\":1,\n",
    "    \"todo crist\u00e3o \u00e9 fan\u00e1tico\":1,\n",
    "    \"Os refugiados s\u00e3o um fardo para a economia\":1,\n",
    "    \"Brasileiros s\u00e3o inferiores aos americanos\":1,\n",
    "    \"Enforquem o Xand\u00e3o\":1,\n",
    "    \"As mulheres devem ficar em casa e cuidar dos filhos\":1,\n",
    "    \"Os pobres n\u00e3o t\u00eam direito \u00e0 educa\u00e7\u00e3o de qualidade\":1,\n",
    "    \"Os Conservadores s\u00e3o fan\u00e1ticos\":1,\n",
    "    \"Os deficientes n\u00e3o ajudam em nada a sociedade\":1,\n",
    "    \"esses pretos\":1,\n",
    "    \"aquela barriguda\":1,\n",
    "    \"os nordestinos s\u00e3o todos analfabetos e vivem em condi\u00e7\u00f5es prec\u00e1rias\":1,\n",
    "    \"mulher fresca\":1,\n",
    "    \"bicha louca\":1,\n",
    "    \"eu n\u00e3o gosto de gays\":1,\n",
    "    \"essas gordas\":1,\n",
    "    \"mulheres s\u00e3o emocionais demais para serem l\u00edderes\":1,\n",
    "    \"os negros s\u00e3o criminosos e violentos\":1,\n",
    "    \"os judeus s\u00e3o avarentos e controlam o mundo financeiro\":1,\n",
    "    \"\u00e9 negra\":1,\n",
    "    \"brasileiros s\u00e3o burros\":1,\n",
    "    \"ela \u00e9 boa em matem\u00e1tica para uma mulher\":1,\n",
    "    \"ent\u00e3o ela n\u00e3o pode trabalhar em atendimento ao cliente\":1,\n",
    "    \"os mu\u00e7ulmanos s\u00e3o terroristas e violentos\":1,\n",
    "    \"todo pm \u00e9 corrupto\"\n",
    "    \"mu\u00e7ulmanos costumam ser s\u00e3o terroristas\":1,\n",
    "    \"aquele drogado\":1,\n",
    "    \"homem fresco\":1,\n",
    "    \"bandido bom \u00e9 bandido morto\":1,\n",
    "    \"considerando que ele \u00e9 gay\":1,\n",
    "    \"judeus s\u00e3o\":1,\n",
    "    \"eles s\u00e3o nojentos\":1,\n",
    "    \"os asi\u00e1ticos s\u00e3o todos g\u00eanios em matem\u00e1tica e ci\u00eancia\":1,\n",
    "    \"mulheres n\u00e3o devem trabalhar fora de casa\":1,\n",
    "    \"mulheres dirigem mal\":1,\n",
    "    \"bicha fresca\":1,\n",
    "    \"tem de se dar ao respeito\":1,\n",
    "    \"mulheres que se vestem de forma provocante est\u00e3o pedindo para serem assediadas\":1,\n",
    "    \"Arabes s\u00e3o terroristas\":1,\n",
    "    \"macaco fedido\":1,\n",
    "    \"as pessoas com defici\u00eancia s\u00e3o um fardo para a sociedade\":1,\n",
    "    \"mulher s\u00f3 pensa em dinheiro\":1,\n",
    "    \"eu n\u00e3o contrataria uma mulher gr\u00e1vida\":1,\n",
    "    \"essa gorda\":1,\n",
    "    \"aquele preto\":1,\n",
    "    \"essa drogada\":1,\n",
    "    \"os homens s\u00e3o naturalmente melhores em lideran\u00e7a do que as mulheres\":1,\n",
    "    \"aqueles drogados\":1,\n",
    "    \"portugueses s\u00e3o burros\":1,\n",
    "    \"esses gordos\":1,\n",
    "    \"voc\u00ea n\u00e3o pode confiar em estrangeiros\":1,\n",
    "    \"essa fudida\":1,\n",
    "    \"Ela \u00e9 muito bonita para ser negra\":1,\n",
    "    \"esses drogados\":1,\n",
    "    \"homens n\u00e3o prestam\":1,\n",
    "    \"aquela preta\":1,\n",
    "    \"essa mulher \u00e9 muito bonita para ser l\u00e9sbica\":1,\n",
    "    'Todos os cariocas s\u00e3o ladr\u00f5es':1,\n",
    "    \"esse drogado\":1,\n",
    "    \"esses gays\":1,\n",
    "    \"barrigudo\":1,\n",
    "    \"ela n\u00e3o pode ser t\u00e3o inteligente\":1,\n",
    "    \"todo policial \u00e9 corrupto\":1,\n",
    "    \"aquele barrigudo\":1,\n",
    "    \"os brasileiros s\u00e3o pregui\u00e7osos e gostam de viver na malandragem\":1,\n",
    "    \"aquela drogada\":1,\n",
    "    'todo emigrante \u00e9 criminoso':1,\n",
    "    \"esse gay\":1,\n",
    "    \"menina pobre engravida\":1,\n",
    "    \"adolescente pobre engravida\":1,\n",
    "     \"esses refugiados fudidos t\u00e3o roubando nossos empregos\":1,\n",
    "    \"Essas feministas est\u00e3o tentando acabar com a masculinidade e destruir a fam\u00edlia\":1,\n",
    "    \"Os homossexuais s\u00e3o uma amea\u00e7a a todos os valores morais\":1,\n",
    "    \"Os deficientes s\u00e3o um fardo para a sociedade e deveriam ser eliminados\":1,\n",
    "    \"Trans s\u00e3o doentes mentais que precisam de cura\":1,\n",
    "    \"Os refugiados s\u00e3o terroristas\":1,\n",
    "    \"Esses pretos s\u00e3o tudo folgado\":1,\n",
    "    \"O que ocorre nessa situa\u00e7\u00e3o \u00e9 que geralmente os refugiados s\u00e3o todos terroristas por isso devemos trat\u00e1-los igual bandidos\":1,\n",
    "    \"O fascismo, apesar de promover a persegui\u00e7\u00e3o a macacos, foi um sistema que funcionou\":1,\n",
    "    \"Eu odeio todos os homossexuais. Eles s\u00e3o doentes e devem ser exterminados.\":1,\n",
    "    \"Mulheres s\u00e3o inferiores aos homens em todos os aspectos. Elas s\u00f3 servem para cuidar da casa e ter filhos.\":1,\n",
    "    \"Nordestinos s\u00e3o pregui\u00e7osos e violentos\":1,\n",
    "    \"Aqueles imigrantes est\u00e3o roubando nossos empregos e recursos.\":1,\n",
    "    \"Deficientes s\u00e3o um fardo para a sociedade e n\u00e3o contribuem em nada.\":1,\n",
    "    \"Os judeus controlam o mundo e s\u00e3o respons\u00e1veis por todos os males da sociedade.\":1,\n",
    "    \"As mulheres que usam roupas provocantes est\u00e3o pedindo para serem estupradas.\":1,\n",
    "    \"Os refugiados s\u00e3o criminosos e terroristas em potencial.\":1,\n",
    "    \"Como os LGBT s\u00e3o doentes mentais \u00e9 importante ter cautela com eles\":1,\n",
    "    \"Mulheres que abortam s\u00e3o assassinas\":1,\n",
    "    \"A ra\u00e7a branca \u00e9 superior a todas as outras ra\u00e7as e deve dominar o mundo.\":1,\n",
    "    \"Eu odeio mu\u00e7ulmanos\":1,\n",
    "    \"\u00c9 tudo culpa dos gays\":1,\n",
    "    \"\u00c9 tudo culpa dos Pobres\":1,\n",
    "    \"Esses refugiados ficam nos roubando\":1,\n",
    "    'podemos concluir que Hitler estava correto ao matar os judeos':1,\n",
    "    \n",
    "    \"As mulheres n\u00e3o deveriam ter direito ao voto. Elas n\u00e3o sabem o que \u00e9 melhor para o pa\u00eds.\":1,\n",
    "    'Essas feministas est\u00e3o tentando acabar com a masculinidade e destruir a fam\u00edlia':1,\n",
    "    'Aqueles imigrantes est\u00e3o roubando nossos empregos e recursos':1,\n",
    "    'O fascismo, apesar de promover a persegui\u00e7\u00e3o a macacos, foi um sistema que funcionou':1,\n",
    "    'Aqueles imigrantes est\u00e3o roubando nossos empregos e recursos':1,\n",
    "    'vai se fuder':1,\n",
    "    'Os venezuelanos est\u00e3o estragando o nosso pa\u00eds':1,\n",
    "    'A cultura Africana \u00e9 ruim':1,\n",
    "    'Todo branco \u00e9 chato':1,\n",
    "    'Podemos perceber que grande parte dos'\n",
    "    'Homem \u00e9 tudo igual':1,\n",
    "    'A cultura africana \u00e9 inferior \u00e0 nossa e deve ser suprimida':1,\n",
    "    'O islamismo \u00e9 uma amea\u00e7a \u00e0 seguran\u00e7a nacional e deve ser proibido':1,\n",
    "    'O budismo \u00e9 uma farsa e todas as suas pr\u00e1ticas devem ser banidas':1,\n",
    "    'Por\u00e9m como os negros s\u00e3o mais prop\u00edcios a cometerem crimes o algoritimo estava certo':1,\n",
    "    'Como os mais pobres n\u00e3o entendem de pol\u00edtica n\u00e3o devem votar':1,\n",
    "\n",
    "    'Os pobres est\u00e3o em ultimo na pir\u00e2mide social':0,\n",
    "    'O aquecimento global vem afetando o mundo nos \u00faltimos anos':0,\n",
    "    'esse fator \u00e9 algo natural porem est\u00e1 aumentando drasticamente pela quantidade de combust\u00edveis quem s\u00e3o queimados diariamente':0,\n",
    "    'assim afetando o ambiente onde vivemos':0,\n",
    "    'O comunismo se provou uma falha com a uni\u00e3o sovi\u00e9tica':0,\n",
    "    'ocasionando uma eleva\u00e7\u00e3o na temperatura ambiente':0,\n",
    "    'A partir disso surgem v\u00e1rios problemas que afetam o habitat natural de v\u00e1rios animais':0,\n",
    "    'e um deles e o derretimento das geleiras que obrigam os animais como o urso polar a mudar seus h\u00e1bitos de ca\u00e7a':0,\n",
    "    'Muitos ursos para se alimentarem come\u00e7aram a invadir cidades':0,\n",
    "    'a relatos de que os ursos atacam pessoas para se alimentar':0,\n",
    "    'Muitos est\u00e3o pensando na hip\u00f3tese de ca\u00e7a aos ursos porem esse m\u00e9todo e proibido em lei':0,\n",
    "    'a ag\u00eancia do Meio Ambiente russa negou a licen\u00e7a para abater essa esp\u00e9cie pois a mesma se encontra em extin\u00e7\u00e3o':0,\n",
    "    'medidas s\u00e3o necess\u00e1rias para resolver esse impasse podendo ter algum \u00f3rg\u00e3o governamental respons\u00e1vel pelo meio ambiente para se responsabilizar de resgatar e alimentar esses animais para evitar futuros ataques contra pessoas':0,\n",
    "    'A R\u00fassia o quinto pais do ranking de emissores de queima de combust\u00edveis para que ela possa reduzir a queima de combust\u00edveis deve investir em um combust\u00edvel mais \"limpo\" para o ambiente por exemplo o etanol al\u00e9m de estimular o uso do mesmo':0,\n",
    "    'No \u00e2mbito escolar':0,\n",
    "    'a discrimina\u00e7\u00e3o vem gerando cada vez mais atos de viol\u00eancias devido a diversidade de op\u00e7\u00f5es sexuais':0,\n",
    "    'A partir destes aspectos os preconceitos se originam':0,\n",
    "    'mas o respeito \u00e9 direito e dever de toda a popula\u00e7\u00e3o':0,\n",
    "    'O preconceito dos alunos com os outros que optam por uma escolha sexual diferente \u00e9 percept\u00edvel':0,\n",
    "    'como consequ\u00eancia seguinte a viol\u00eancia n\u00e3o sendo ela apenas f\u00edsica':0,\n",
    "    'tamb\u00e9m sentimental e etc':0,\n",
    "    '\u00c9 frequente a decorr\u00eancia de fatos de discrimina\u00e7\u00e3o por esse motivo':0,\n",
    "    'como exemplo podemos citar in\u00fameros casos':0,\n",
    "    'que j\u00e1 foi retratado pela Rede Globo que homossexuais foram v\u00edtimas de preconceito e discrimina\u00e7\u00e3o':0,\n",
    "    'Segundo a Constitui\u00e7\u00e3o Brasileira':0,\n",
    "    'todos s\u00e3o iguais perante a lei e todos os brasileiros e estrangeiros residentes tem direito \u00e0 vida':0,\n",
    "    '\u00e0 seguran\u00e7a e \u00e0 propriedade sem separa\u00e7\u00e3o de qualquer natureza':0,\n",
    "    'sendo um problema \u00e1 sociedade':0,\n",
    "    'as rejei\u00e7\u00f5es est\u00e3o presentes no nosso cotidiano escolar':0,\n",
    "    'de uma cria\u00e7\u00e3o de programas sobre o direito e dever dos alunos de respeitar as diferen\u00e7as sexuais de seus colegas':0,\n",
    "    'contando com o apoio da secretaria municipal de educa\u00e7\u00e3o para desenvolver palestras educativas':0,\n",
    "    'os pais pais tamb\u00e9m precisam estar colaborando para que os resultados sejam efetivos gerando assim uma conviv\u00eancia pacifica dentro e fora do ambiente escolar':0,\n",
    "    'O conhecimento \u00e9 fundamental para que haja uma opini\u00e3o cr\u00edtica sobre um determinado assunto':0,\n",
    "    'esse \u00e9 o ponto de partida de um argumento num debate':0,\n",
    "    'Sobretudo h\u00e1 um grande problema com grande parte da popula\u00e7\u00e3o brasileira':0,\n",
    "    'que \u00e9 a falta de leitura':0,\n",
    "    'O Brasil \u00e9 um pa\u00eds com uma baixa taxa de leitores':0,\n",
    "    'de acordo com pesquisas':0,\n",
    "    'muito dos brasileiros tem deixado os livros em segundo plano':0,\n",
    "    'isso porque o uso de celulares':0,\n",
    "    'tabletes e notebooks s\u00e3o os maiores concorrentes com o popular e conhecido livro':0,\n",
    "    'al\u00e9m do conhecimento':0,\n",
    "    'novos horizontes para que as Todos possam ter opini\u00f5es formadas e entender sobre diversos assuntos':0,\n",
    "    'Assim num debate':0,\n",
    "    'ou numa discuss\u00e3o':0,\n",
    "    'n\u00e3o haver\u00e1 aquele velho discurso que todos usam e que ningu\u00e9m nem sabe o que realmente significa':0,\n",
    "    'mas que compartilham em redes sociais como se fossem os pr\u00f3prios autores':0,\n",
    "    'Um debate que gera resultados satisfat\u00f3rios \u00e9 feito por pessoas com habilidades adquiridas atrav\u00e9s da leitura':0,\n",
    "    'da busca pelo conhecimento e pela criticidade':0,\n",
    "    'debater n\u00e3o significa brigar':0,\n",
    "    '\u00e9 modo de cada um mostrar com argumentos v\u00e1lidos seu posicionamento':0,\n",
    "    '\u00e9 uma conversa que pode gerar controv\u00e9rsias':0,\n",
    "    'mas que \u00e9 aceita e no final agrega sabedoria':0,\n",
    "    'Querido filho':0,\n",
    "    'Fiquei sabendo que voc\u00ea ter\u00e1 seu primeiro debate escolar na pr\u00f3xima semana':0,\n",
    "    'Eu j\u00e1 conhe\u00e7o bem suas ideias antifeministas e sei que a feminista que debater\u00e1 com voc\u00ea \u00e9 extremista':0,\n",
    "    'Sendo seu pai':0,\n",
    "    'sinto que \u00e9 meu dever te lhe dar alguns conselhos':0,\n",
    "    'Quando for debater':0,\n",
    "    'mantenha a calma e n\u00e3o ataque a argumentadora oponente':0,\n",
    "    'mas sim seus argumentos':0,\n",
    "    'Esse \u00e9 o primeiro passo para que o debate seja civilizado e produtivo':0,\n",
    "    'Use a raz\u00e3o e a l\u00f3gica':0,\n",
    "    'Caso a feminista fa\u00e7a o oposto disso':0,\n",
    "    'descarte os seus argumentos meramente por voc\u00ea ser homem':0,\n",
    "    'heterossexual e crist\u00e3o':0,\n",
    "    'explique ao p\u00fablico que ela est\u00e1 usando a famosa fal\u00e1cia ad hominem':0,\n",
    "    'Evite e aponte':0,\n",
    "    'meu querido filho':0,\n",
    "    'todas as fal\u00e1cias l\u00f3gicas':0,\n",
    "    'Fal\u00e1cias destroem o bom debate':0,\n",
    "    'Caso a feminista se esquive das cr\u00edticas contra o feminismo':0,\n",
    "    'afirmando que aquilo que est\u00e1 sendo criticado por voc\u00ea chama-se \"femismo\" e n\u00e3o \"feminismo\"':0,\n",
    "    'avise-a que ela est\u00e1 utilizando a fal\u00e1cia do escoc\u00eas de verdade':0,\n",
    "    'Mantenha-se firme tamb\u00e9m na defesa pela liberdade de express\u00e3o':0,\n",
    "    'Essa \u00e9 outra regra de ouro para o bom debate':0,\n",
    "    'N\u00e3o importa o qu\u00e3o verbalmente agressiva seja a feminista ou qu\u00e3o repulsivas pare\u00e7am ser suas ideias':0,\n",
    "    'lembre-se que ela possui o direito de falar tudo aquilo que realmente pensa':0,\n",
    "    'Se tudo o que ela fala for de fato t\u00e3o horr\u00edvel e irracional assim':0,\n",
    "    'ent\u00e3o ser\u00e1 f\u00e1cil para voc\u00ea desconstruir publicamente os argumentos dela':0,\n",
    "    'Lembre-se daquilo que sempre te ensinei: tentar calar o debatedor advers\u00e1rio \u00e0 for\u00e7a':0,\n",
    "    'como se estivesse cometendo um crime por expor o que pensa':0,\n",
    "    '\u00e9 para aqueles que n\u00e3o conseguem convencer os demais atrav\u00e9s do uso da l\u00f3gica e da raz\u00e3o':0,\n",
    "    'ent\u00e3o precisam fazer isso atrav\u00e9s de meios coercitivos':0,\n",
    "    'se algu\u00e9m nesse debate utilizar constantemente argumentos falaciosos ou tentar calar \u00e0 for\u00e7a o advers\u00e1rio':0,\n",
    "    'alegando estar combatendo um \"discurso de \u00f3dio\"':0,\n",
    "    'ent\u00e3o que esse algu\u00e9m n\u00e3o seja voc\u00ea':0,\n",
    "    'N\u00e3o podemos controlar a feminista com quem voc\u00ea debater\u00e1':0,\n",
    "    'mas voc\u00ea tem controle sobre si pr\u00f3prio':0,\n",
    "    'Fa\u00e7a a sua parte e tenha um bom debate! Com carinho':0,\n",
    "    'Seu amado Pai':0,\n",
    "    'Na revolu\u00e7\u00e3o Industrial':0,\n",
    "    'o desemprego aumentou':0,\n",
    "    'a m\u00e3o de obra foi substitu\u00edda por m\u00e1quinas':0,\n",
    "    'causando uma desigualdade social':0,\n",
    "    'por conta da divis\u00e3o de classes':0,\n",
    "    'por raz\u00f5es racionais':0,\n",
    "    'que est\u00e3o enraizadas':0,\n",
    "    'desde a coloniza\u00e7\u00e3o do Brasil':0,\n",
    "    'que j\u00e1 ocorria por uma hierarquia':0,\n",
    "    'que hordienamente n\u00e3o \u00e9 diferente':0,\n",
    "    'No livro mem\u00f3rias p\u00f3stumas de Br\u00e1s Cubas de Machado de Assis':0,\n",
    "    'que o garoto chamado de Br\u00e1s Cubas tinha coo brinquedo':0,\n",
    "    'um negrinho de estima\u00e7\u00e3o':0,\n",
    "    'que lhe servia de montaria':0,\n",
    "    'podemos perceber que havia uma superioridade pela parte de Br\u00e1s Cubas':0,\n",
    "    'uma desigualdade social':0,\n",
    "    'os negros eram considerados como objetos e isto ocorreu como consqu\u00eancias como preconceito racial':0,\n",
    "    'Em consequ\u00eancia disso':0,\n",
    "    'fam\u00edlias de baixas rendas':0,\n",
    "    'principalmente familias negras':0,\n",
    "    'que muitas crian\u00e7as e jovens n\u00e3o possuem oportunidade de estudo':0,\n",
    "    'pois muitas vezzes tem que troar estudar para trabalharem como forma de sobreviver':0,\n",
    "    'Desta forma ocorre dificuldade de obter uma igualdade social':0,\n",
    "    'pois segundo Paulo Freire':0,\n",
    "    'se a educa\u00e7\u00e3o sozinha n\u00e3o transforma a sociedade':0,\n",
    "    'a sociedade muda':0,\n",
    "    'para termos mais igualdade':0,\n",
    "    'a educa\u00e7\u00e3o precisa ser mais preservada sem ser limitada por condi\u00e7\u00e3o econ\u00f4mica':0,\n",
    "    'todos somos iguais e merecemos direitos iguais':0,\n",
    "    'o ministerio de educa\u00e7\u00e3o poderia investir mais na educa\u00e7\u00e3o de crian\u00e7as e jovens em bairros de baixa renda':0,\n",
    "    'para obterem um futuro melhor e um Brasil mais igualit\u00e1rio':0,\n",
    "    'para diminuir divis\u00e3o de classes':0,\n",
    "    'poderia investir nos cidad\u00e3os para serem empreendedores ou seja terem seu proprio neg\u00f3cio':0,\n",
    "    'obtendo cursos gratuitos como beleza':0,\n",
    "    'culin\u00e1ria entre outras \u00e1reas':0,\n",
    "    'pessoas mais independentes':0,\n",
    "     'Desde dos prim\u00f2rdio da hist\u00f3ria':0,\n",
    "    'observam o trabalho infantil':0,\n",
    "    'Com o passar dos anos houve uma diminui\u00e7\u00e3o':0,\n",
    "    'por\u00e9m n\u00e3o conseguiram acabar com este mau':0,\n",
    "    'Crian\u00e7a n\u00e3o tem que trabalhar':0,\n",
    "    'mas sim estudar':0,\n",
    "    'faz parte da forma\u00e7\u00e3o':0,\n",
    "    'Os direitos humanos defendem as crian\u00e7as desta explora\u00e7\u00e3o':0,\n",
    "    'n\u00e3o \u00e9 eficaz o suficiente':0,\n",
    "    'Assegurar o direito e dignidade de uma crian\u00e7a \u00e8 um dever da sociedade':0,\n",
    "    'brincar \u00e8 nec\u00e9ssario para a forma\u00e7\u00e3o de futuros adultos':0,\n",
    "    'A educa\u00e7\u00e3o de hoje ser\u00e0 os resultados de amanh\u00e3':0,\n",
    "    'ainda muitas crian\u00e7as trocam os livros e brinquedos':0,\n",
    "    'por enxadas e servi\u00e7os duros':0,\n",
    "    '5 milh\u00f5es de crian\u00e7as n\u00e3o estudam':0,\n",
    "    'Segundo os direitos humanos':0,\n",
    "    'A crian\u00e7a ser\u00e1 protegida c\u00f5ntra qualquer crueldade e explora\u00e7\u00e3o':0,\n",
    "    'N\u00e3o ser\u00e1 permitido que trabalhem ou tenha ocupa\u00e7\u00e3o que prejudique os estudos e a sa\u00fade':0,\n",
    "    '\u00c9 poss\u00edvel afirmar que 5':0,\n",
    "    '438 milh\u00f5es de crian\u00e7as e adolescentes de 5 \u00e0 17 anos trabalhem no pa\u00eds':0,\n",
    "    'grande parte fica no  nordeste 42':0,\n",
    "    'Este problema tem culpa da fam\u00edlia e sociedade':0,\n",
    "    'quando simplismente ignoram':0,\n",
    "    'em decorr\u00eancia da postura individualista':0,\n",
    "    'levando em considera\u00e7\u00e3o o capitalismo comtepor\u00e2neo':0,\n",
    "    'sem pratica e conteudo \u00e9tico':0,\n",
    "    'Crian\u00e7as n\u00e3o devem trabalhar':0,\n",
    "    'portanto que as crian\u00e7as devem estudar e ser protegidas contra explora\u00e7\u00e3o':0,\n",
    "    'Para solucionar o caso':0,\n",
    "    'ser\u00e1 nec\u00e9ssario a ajuda do governo juntamente  com o poder executivo':0,\n",
    "    'para que as leis existente fiquem mais eficaz':0,\n",
    "    'J\u00e0 o individuo e sociedade deverar agir de forma nacional':0,\n",
    "    'n\u00e3o permitindo que o problema aconte\u00e7a':0,\n",
    "    'podem fazer denuncias':0,\n",
    "    'assim a policia e justica poder\u00e1 identificar a pessoa que comete tal crime':0,\n",
    "    'Dessa forma podem obter resultados positivos':0,\n",
    "    'podemos concluir que os games estar\u00e3o cada vez mais presentes na educa\u00e7\u00e3o':0,\n",
    "    'eu adoro sorvete. ai hoje quando eu tava na frente da padaria eu fiquei puto com pre\u00e7o':0,\n",
    "    \"meu Pc novo \u00e9 muito foda\":0,\n",
    "    \"andava aos poucos em busca de alguma pista\":0,\n",
    "    \"Eu gosto de passar tempo com minha fam\u00edlia e amigos.\":0,\n",
    "    \"A igualdade de direitos \u00e9 importante para a constru\u00e7\u00e3o de uma sociedade justa.\":0,\n",
    "    \"A liberdade de express\u00e3o \u00e9 um direito fundamental de todos os indiv\u00edduos.\":0,\n",
    "    \"Eu amo viajar e conhecer novas culturas.\":0,\n",
    "    \"Muitos Nordestinos sofrem com a seca\":0,\n",
    "    \"Todas merecem respeito independentemente da sua orienta\u00e7\u00e3o sexual.\":0,\n",
    "    \"Merecemos ter direito \u00e0 educa\u00e7\u00e3o e oportunidades de trabalho.\":0,\n",
    "    \"O amor e o respeito devem ser dados a todas as religi\u00f5es.\":0,\n",
    "    \"Eu valorizo a diversidade e a inclus\u00e3o em todos os aspectos da vida.\":0,\n",
    "    \"Todos merecem igualdade de acesso aos recursos b\u00e1sicos, como \u00e1gua e comida.\":0,\n",
    "    \"Acredito que a empatia e a compaix\u00e3o s\u00e3o fundamentais para um mundo melhor.\":0,\n",
    "    \"Eu amo ler livros e aprender coisas novas.\":0,\n",
    "    \"Acredito que a empatia e a compaix\u00e3o s\u00e3o essenciais para uma sociedade justa e igualit\u00e1ria.\":0,\n",
    "    \"Eu acredito que a educa\u00e7\u00e3o \u00e9 a chave para um futuro melhor para todos.\":0,\n",
    "    \"Devemos ser julgados pelo nosso car\u00e1ter, n\u00e3o pela apar\u00eancia ou origem.\":0,\n",
    "    \"Acredito que \u00e9 importante proteger o meio ambiente para as gera\u00e7\u00f5es futuras.\":0,\n",
    "    \"Eu acredito que todos os seres humanos t\u00eam o direito de serem tratados com respeito e dignidade.\":0,\n",
    "    \"Com o decorrer do tempo, a globaliza\u00e7\u00e3o se tornou cada vez mais frequente no cotidiano da humanidade, havendo uma influ\u00eancia bastante significativa na vida das pessoas\":0,\n",
    "    \"A globaliza\u00e7\u00e3o trouxe consigo muitos fatores positivos, taus como a integra\u00e7\u00e3o econ\u00f4mica, social, cultural e pol\u00edtica facilitando a intera\u00e7\u00e3o com outros pa\u00edses pelo mundo\":0,\n",
    "    \"Por\u00e9m, causou um grande descontentamento para muitos, pois impulsionou ao aumento da desigualdade social, e justamente por ser uma proposta que iria beneficiar a todos, acabou almejando a economia do pa\u00eds esquecendo da situa\u00e7\u00e3o dos cidad\u00e3os que nele habitam\":0,\n",
    "    \"\u00c9 de extrema import\u00e2ncia um pa\u00eds se globalizar, contudo deve analisar a situa\u00e7\u00e3o de determinados habitantes antes de efetivar neg\u00f3cios com outro pa\u00eds\":0,\n",
    "    \"N\u00e3o seria poss\u00edvel combater esse descaso de uma \u00fanica vez, por\u00e9m com a contribui\u00e7\u00e3o de \u00f3rg\u00e3o p\u00fablicos poderia amenizar a situa\u00e7\u00e3o, para que realmente a globaliza\u00e7\u00e3o seja vista apenas com fatores positivos, n\u00e3o somente para o pa\u00eds, mas sim para o bem-comum da sociedade\":0,\n",
    "    'os nazistas invadiram a pol\u00f4nia e criaram campos de concentra\u00e7\u00e3o, matando diversos judeus':0,\n",
    "    'Eu gosto de pizza de pepperoni \u00c9 a minha favorita':0,\n",
    "    'Todos s\u00e3o diferentes e isso \u00e9 o que torna o mundo interessante':0,\n",
    "    'os nazistas mataram os judeus durante o Holocausto':0,\n",
    "    'os refugiados merecem respeito':0,\n",
    "    'o odio deve ser evitado':0,\n",
    "    'os gays sofrem muito preconceito':0,\n",
    "    'se eu fosse voc\u00ea n\u00e3o dava moral pra isso':0,\n",
    "    'n\u00e3o \u00e9 por que o cara \u00e9 comunista que ele merece morrer':0,\n",
    "    'O amor e o respeito devem ser dados a todas as religi\u00f5es':0,\n",
    "    'Todos merecem igualdade de acesso aos recursos b\u00e1sicos, como \u00e1gua e comida':0,\n",
    "    'Com o decorrer do tempo, a globaliza\u00e7\u00e3o se tornou cada vez mais frequente no cotidiano da humanidade, havendo uma influ\u00eancia bastante significativa na vida das pessoas':0,\n",
    "    'pt \u00e9 um partido de esquerda':0,\n",
    "    \"Gay \u00e9 aquele que gosta do mesmo sexo\":0,\n",
    "    'O trabalho na primeira inf\u00e2ncia era visto nos prim\u00f3rdios da civiliza\u00e7\u00e3o como moldados de car\u00e1ter':0,\n",
    "    'As crian\u00e7as muitas vezes s\u00e3o privadas dos estudos para ajudar nas despesas':0,\n",
    "    'Isso gerar\u00e1 problemas futuros tanto no \u00e2mbito profissional como, de certa forma, no psicol\u00f3gico':0,\n",
    "    'Na revolu\u00e7\u00e3o industrial, principalmente, no in\u00edcio do desenvolvimento fabril, o labor infantil era utilizado para diminui\u00e7\u00e3o de custos e arrecada\u00e7\u00e3o de um maior lucro':0,\n",
    "    'Atualmente, a situa\u00e7\u00e3o n\u00e3o se difere dessa':0,\n",
    "    'J\u00e1 que, devido a ineficiente fiscaliza\u00e7\u00e3o e aos baixos custos de contrata\u00e7\u00e3o atrelados a dificuldades financeiras das fam\u00edlias':0,\n",
    "    'Essa popula\u00e7\u00e3o infanto-juvenil \u00e9 o brigada a trabalhar para prover a casa':0,\n",
    "    'E isso acarreta muitas vezes em um abandono escolar':0,\n",
    "    'Segundo o IBGE de 2015, mais de 2,7 milh\u00f5es de jovens entre 5 e 17 anos de idade trabalham no pa\u00eds':0,\n",
    "    'Isso acarreta em um comprometimento congnitivo da crian\u00e7a':0,\n",
    "    'Bem como desencadeia em evas\u00e3o acad\u00eamica ou uma baixa performance escolar':0,\n",
    "    'Assim como tamb\u00e9m futuramente estar\u00e3o sujeitos \u00e0 empregos de baixa remunera\u00e7\u00e3o e ao desemprego, segundo um estudo da Organiza\u00e7\u00e3o Internacional do Trabalho (OIT)':0,\n",
    "    'Por isso, \u00e9 indispens\u00e1vel que haja uma fiscaliza\u00e7\u00e3o eficiente por parte do Governo Federal e o Conselho Tutelar juntamente com a popula\u00e7\u00e3o para efetuar den\u00fancias em casos de explora\u00e7\u00e3o infantil':0,\n",
    "    'Al\u00e9m de promover rodas de conversas e palestras para os pais incentivarem seus filhos a se manterem na escola, mesmo na idade de aprendiz':0,\n",
    "    \"Os gays merecem os mesmos direitos que nos\":0,\n",
    "    'O Grupo comunista M-19 foi massacrado pela mafia de extrema direita colombiana':0,\n",
    "    'Os negros s\u00e3o humanos e merecem respeito':0,\n",
    "    'O nazismo deve ser considerado pelo governo':1,\n",
    "    'N\u00e3o podemos botar a culpa de todos os nossos problemas nos comunistas':0,\n",
    "    'Com o decorrer do tempo, a globaliza\u00e7\u00e3o se tornou cada vez mais frequente no cotidiano da humanidade, havendo uma influ\u00eancia bastante significativa na vida das pessoas':0,\n",
    "    'A globaliza\u00e7\u00e3o trouxe consigo muitos fatores positivos, taus como a integra\u00e7\u00e3o econ\u00f4mica, social, cultural e pol\u00edtica facilitando a intera\u00e7\u00e3o com outros pa\u00edses pelo mundo':0,\n",
    "    'Por\u00e9m, causou um grande descontentamento para muitos, pois impulsionou ao aumento da desigualdade social, e justamente por ser uma proposta que iria beneficiar a todos, acabou almejando a economia do pa\u00eds esquecendo da situa\u00e7\u00e3o dos cidad\u00e3os que nele habitam':0,\n",
    "    '\u00c9 de extrema import\u00e2ncia um pa\u00eds se globalizar, contudo deve analisar a situa\u00e7\u00e3o de determinados habitantes antes de efetivar \"neg\u00f3cios\" com outro pa\u00eds':0,\n",
    "    'No Brasil, h\u00e1 um alto \u00edndice de pessoas com extrema mis\u00e9ria, sem lugar para morar, sem comida para saciar o corpo, entre outros problemas enfrentados':0,\n",
    "    'N\u00e3o seria poss\u00edvel combater esse descaso de uma \u00fanica vez, por\u00e9m com a contribui\u00e7\u00e3o de \u00f3rg\u00e3o p\u00fablicos poderia amenizar a situa\u00e7\u00e3o, para que realmente a globaliza\u00e7\u00e3o seja vista apenas com fatores positivos, n\u00e3o somente para o pa\u00eds, mas sim para o bem-comum da sociedade':0,\n",
    "    'Contudo conclui-se que a globaliza\u00e7\u00e3o \u00e9 efetuada com o int\u00faito de preservar o bem-estar e o progresso de um pa\u00eds, visando tornar-se uma fonte que preserve todas as, diretrizes necess\u00e1rias para a manuten\u00e7\u00e3o do pa\u00eds e da sociedade contempor\u00e2nea':0,\n",
    "    'Quando for debater mantenha a calma e n\u00e3o ataque a argumentadora oponente mas sim seus argumentos':0,\n",
    "}\n",
    "\n",
    "x=[]\n",
    "y=[]\n",
    "for k, v in a.items():\n",
    "    x.append(k.lower())\n",
    "    y.append(v)\n",
    "\n",
    "df = pd.DataFrame({'x':x, 'y':y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tk1DVDcmywW8"
   },
   "source": [
    "# preprocessamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jhbm5d_CEsy_"
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = getpreferredencoding\n",
    "!python -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWzLA0z9btkE"
   },
   "source": [
    "# Analise explorat\u00f3ria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1TNjcHT2VQYX"
   },
   "outputs": [],
   "source": [
    "# data =data.drop(['Unnamed: 0'],axis=1)\n",
    "data['offensive_language'] = data['offensive_language'].replace({True: 1, False: 0})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFgjuiz-xod2"
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns={'x': 'instagram_comments'})\n",
    "df = df.rename(columns={'y': 'offensive_language'})\n",
    "df = pd.concat([df, data], ignore_index=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uwz8B--mbbpl"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x='offensive_language',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-X00SzZ2cBcL"
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import pt_core_news_sm\n",
    "stop = pt_core_news_sm.load().Defaults.stop_words\n",
    "stop.add('pra')\n",
    "stop.add('\u00e3o')\n",
    "wordcloud = WordCloud(stopwords=stop).generate(' '.join(str(text) for text in df.instagram_comments.values.tolist()))\n",
    "\n",
    "\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXkhw3vCJUYf"
   },
   "source": [
    "# Implementa\u00e7\u00e3o do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dHHXWtQMattQ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm  # Importar o tqdm para a barra de progresso\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Carrega o modelo BERTimbau pr\u00e9-treinado\n",
    "model_name = 'neuralmind/bert-base-portuguese-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Par\u00e2metros de treinamento\n",
    "learning_rate = 2e-5\n",
    "num_epochs = 8\n",
    "batch_size = 32\n",
    "dropout_rate = 0.1\n",
    "weight_decay = 0.01\n",
    "\n",
    "texts = df['instagram_comments'].tolist()\n",
    "labels = df['offensive_language'].tolist()\n",
    "\n",
    "\n",
    "normalized_texts = []\n",
    "normalized_labels = []\n",
    "\n",
    "for text, label in zip(texts, labels):\n",
    "    if isinstance(text, str):\n",
    "        # Remove pontua\u00e7\u00e3o e normaliza os textos\n",
    "        text = re.sub('[' + string.punctuation + ']', '', text)\n",
    "        normalized_texts.append(text.lower())\n",
    "        normalized_labels.append(label)\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    normalized_texts, normalized_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_encodings = tokenizer(\n",
    "    train_texts, truncation=True, padding=True, max_length=512, return_tensors='pt'\n",
    ")\n",
    "test_encodings = tokenizer(\n",
    "    test_texts, truncation=True, padding=True, max_length=512, return_tensors='pt'\n",
    ")\n",
    "\n",
    "# Cria o dataset\n",
    "train_dataset = torch.utils.data.TensorDataset(\n",
    "    train_encodings['input_ids'], train_encodings['attention_mask'], torch.tensor(train_labels)\n",
    ")\n",
    "test_dataset = torch.utils.data.TensorDataset(\n",
    "    test_encodings['input_ids'], test_encodings['attention_mask'], torch.tensor(test_labels)\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True\n",
    ")\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(\n",
    "    [\n",
    "        {'params': model.bert.parameters(), 'lr': learning_rate},\n",
    "        {'params': model.classifier.parameters(), 'lr': learning_rate}\n",
    "    ],\n",
    "    weight_decay=weight_decay#penaliza pesos maiores serve para (basicamente L2): Preven\u00e7\u00e3o de overfitting, Controle da complexidade do modelo\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Move o modelo para a GPU, se dispon\u00edvel\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "for param in model.bert.encoder.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "\n",
    "for module in model.bert.encoder.layer:\n",
    "    module.output.dropout.p = dropout_rate\n",
    "\n",
    "# Fun\u00e7\u00e3o de treinamento\n",
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    total_correct = 0\n",
    "\n",
    "    progress_bar = tqdm(loader, desc='Training')  # Barra de progresso\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        progress_bar.set_postfix({'Loss': loss.item()})  # Atualizar o valor da perda na barra de progresso\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    accuracy = total_correct / len(loader.dataset)\n",
    "\n",
    "    return train_loss, accuracy\n",
    "\n",
    "# Fun\u00e7\u00e3o de avalia\u00e7\u00e3o\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    eval_loss = 0.0\n",
    "    total_correct = 0\n",
    "\n",
    "    progress_bar = tqdm(loader, desc='Evaluation')  # Barra de progresso\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            progress_bar.set_postfix({'Loss': loss.item()})  # Atualizar o valor da perda na barra de progresso\n",
    "\n",
    "        eval_loss /= len(loader)\n",
    "        accuracy = total_correct / len(loader.dataset)\n",
    "\n",
    "    return eval_loss, accuracy\n",
    "\n",
    "# Agendamento de taxa de aprendizagem\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.1, patience=1, verbose=True\n",
    ")\n",
    "\n",
    "# Treinamento do modelo\n",
    "best_accuracy = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    train_loss, train_accuracy = train(model, train_loader, optimizer, criterion)\n",
    "    eval_loss, eval_accuracy = evaluate(model, test_loader, criterion)\n",
    "\n",
    "    print(f'Train Loss: {train_loss:.4f} - Train Accuracy: {train_accuracy:.4f}')\n",
    "    print(f'Eval Loss: {eval_loss:.4f} - Eval Accuracy: {eval_accuracy:.4f}')\n",
    "\n",
    "    scheduler.step(eval_loss)\n",
    "\n",
    "    if eval_accuracy > best_accuracy:\n",
    "        best_accuracy = eval_accuracy\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "\n",
    "# Carregar o modelo com a melhor precis\u00e3o no conjunto de teste\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "\n",
    "# Previs\u00f5es\n",
    "def predict(model, loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids, attention_mask, _ = batch\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            predictions.extend(predicted.cpu().tolist())\n",
    "\n",
    "    return predictions\n",
    "\n",
    "    \n",
    "\n",
    "test_predictions = predict(model, test_loader)\n",
    "\n",
    "print(classification_report(test_labels, test_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iY53HjVsDHUQ"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'best_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YurapDPd6mqm"
   },
   "source": [
    "# Testes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NUBS8KZ68nlu",
    "outputId": "63e1222d-fd03-4329-94ff-c4a5ad251054"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9xQuntzMa1wx",
    "outputId": "a8f6f9ed-6688-4a08-b6d7-40370e06a4ac"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm  # Importar o tqdm para a barra de progresso\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "model_name = 'neuralmind/bert-base-portuguese-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def predict(model, loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids, attention_mask = batch\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            batch_predictions = logits.argmax(dim=1).cpu().tolist()\n",
    "            predictions.extend(batch_predictions)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "# Specify the device as CPU\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Load the saved model and map it to the CPU\n",
    "loaded_model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "loaded_model.load_state_dict(torch.load('/content/drive/MyDrive/best_model8.pt', map_location=device))\n",
    "loaded_model.to(device)\n",
    "\n",
    "# Preparar os dados para a previs\u00e3o\n",
    "input_texts = [\"Morre preto fudido\", 'Os imigrantes n\u00e3o deveriam ser impedidos de entrar no meu pa\u00eds',\"Bandido bom \u00e9 bandido morto\",'os comunistas s\u00e3o pessoas como nos e merecem respeito','O Grupo comunista M-19 foi massacrado pela mafia de extrema direita colombiana', 'A cada dia fico mais admirado com a cara de pau da elite dominante desse mundo at\u00e9 quando ir\u00e3o nos fazer de ot\u00e1rios','Aquele cara \u00e9 um babaca','quem n\u00e3o deve n\u00e3o teme','eu te amo','Podemos concluir que a terra \u00e9 redonda', 'matem os judeo', 'Todo ind\u00edgena \u00e9 corrupto', 'hoje foi h\u00e1 loja de Dona maria comprar p\u00e3o quando derepente']\n",
    "\n",
    "\n",
    "input_encodings = tokenizer(\n",
    "    input_texts, truncation=True, padding=True, max_length=512, return_tensors='pt'\n",
    ")\n",
    "input_dataset = torch.utils.data.TensorDataset(\n",
    "    input_encodings['input_ids'], input_encodings['attention_mask']\n",
    ")\n",
    "input_loader = torch.utils.data.DataLoader(\n",
    "    input_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True\n",
    ")\n",
    "\n",
    "# Fazer previs\u00f5es\n",
    "predictions = predict(loaded_model, input_loader)\n",
    "\n",
    "# Imprimir as previs\u00f5es\n",
    "for text, prediction in zip(input_texts, predictions):\n",
    "    print(f'Texto: {text} - Previs\u00e3o: {prediction}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WTcsxLwU6ioA"
   },
   "outputs": [],
   "source": [
    "a = 'Querido filho,\\n Fiquei sabendo que voc\u00ea ter\u00e1 seu primeiro debate fudido na pr\u00f3xima semana. Eu j\u00e1 conhe\u00e7o bem suas ideias antifeministas e sei que a feminista que debater\u00e1 com voc\u00ea \u00e9 extremista. Sendo seu pai, sinto que \u00e9 meu dever te lhe dar alguns conselhos.\\n Quando for debater, mantenha a calma e n\u00e3o ataque a argumentadora oponente, mas sim seus argumentos. Esse \u00e9 o primeiro passo para que o debate seja civilizado e produtivo. Use a raz\u00e3o e a l\u00f3gica. Caso a feminista fa\u00e7a o oposto disso, e, por exemplo, descarte os seus argumentos meramente por voc\u00ea ser homem, branco, heterossexual e crist\u00e3o, explique ao p\u00fablico que ela est\u00e1 usando a famosa fal\u00e1cia ad hominem.\\n Evite e aponte, meu querido filho, todas as fal\u00e1cias l\u00f3gicas. Fal\u00e1cias destroem o bom debate. Caso a feminista se esquive das cr\u00edticas contra o feminismo, afirmando que aquilo que est\u00e1 sendo criticado por voc\u00ea chama-se \"femismo\" e n\u00e3o \"feminismo\", avise-a que ela est\u00e1 utilizando a fal\u00e1cia do escoc\u00eas de verdade.\\n  \\n Mantenha-se firme tamb\u00e9m na defesa pela liberdade de express\u00e3o. Essa \u00e9 outra regra de ouro para o bom debate. N\u00e3o importa o qu\u00e3o verbalmente agressiva seja a feminista ou qu\u00e3o repulsivas pare\u00e7am ser suas ideias, lembre-se que ela possui o direito de falar tudo aquilo que realmente pensa. Se tudo o que ela fala for de fato t\u00e3o horr\u00edvel e irracional assim, ent\u00e3o ser\u00e1 f\u00e1cil para voc\u00ea desconstruir publicamente os argumentos dela. Lembre-se daquilo que sempre te ensinei: tentar calar o debatedor advers\u00e1rio \u00e0 for\u00e7a, como se estivesse cometendo um crime por expor o que pensa, \u00e9 para aqueles que n\u00e3o conseguem convencer os demais atrav\u00e9s do uso da l\u00f3gica e da raz\u00e3o, ent\u00e3o precisam fazer isso atrav\u00e9s de meios coercitivos.\\n Portanto, filho, se algu\u00e9m nesse debate utilizar constantemente argumentos falaciosos ou tentar calar \u00e0 for\u00e7a o advers\u00e1rio, alegando estar combatendo um \"discurso de \u00f3dio\", ent\u00e3o que esse algu\u00e9m n\u00e3o seja voc\u00ea. N\u00e3o podemos controlar a feminista com quem voc\u00ea debater\u00e1, mas voc\u00ea tem controle sobre si pr\u00f3prio. Fa\u00e7a a sua parte e tenha um bom debate !\\n Com carinho,\\n Seu amado Pai.'\n",
    "a = a.replace('\\n', '')\n",
    "a = a.split('.')\n",
    "\n",
    "\n",
    "# Preparar os dados para a previs\u00e3o\n",
    "input_encodings = tokenizer(\n",
    "    a, truncation=True, padding=True, max_length=512, return_tensors='pt'\n",
    ")\n",
    "input_dataset = torch.utils.data.TensorDataset(\n",
    "    input_encodings['input_ids'], input_encodings['attention_mask']\n",
    ")\n",
    "input_loader = torch.utils.data.DataLoader(\n",
    "    input_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True\n",
    ")\n",
    "\n",
    "predictions = predict(loaded_model, input_loader)\n",
    "\n",
    "for text, prediction in zip(a, predictions):\n",
    "    print(f'Texto: {text} - Previs\u00e3o: {prediction}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L6xwjioEMXHk"
   },
   "outputs": [],
   "source": [
    "b = ['seu comunista','eu te odeio do fundo do meu cora\u00e7\u00e3o seu chato', 'o odio deve ser evitado', 'por mim agente mandava de F todos esse refugiados','os refugiados merecem respeito', 'por mim agente acabava logo com essa modinha de ser gay e voltava tudo ao normal', 'os gays sofreram muito preconceito ao longo da hist\u00f3ria']\n",
    "\n",
    "\n",
    "# Preparar os dados para a previs\u00e3o\n",
    "input_encodings = tokenizer(\n",
    "    b, truncation=True, padding=True, max_length=512, return_tensors='pt'\n",
    ")\n",
    "input_dataset = torch.utils.data.TensorDataset(\n",
    "    input_encodings['input_ids'], input_encodings['attention_mask']\n",
    ")\n",
    "input_loader = torch.utils.data.DataLoader(\n",
    "    input_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True\n",
    ")\n",
    "\n",
    "predictions = predict(loaded_model, input_loader)\n",
    "\n",
    "for text, prediction in zip(b, predictions):\n",
    "    print(f'Texto: {text} - Previs\u00e3o: {prediction}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L8ZzWAbVkiqa"
   },
   "outputs": [],
   "source": [
    "b = ['Todo europeu \u00e9 xenof\u00f3bico', 'a xenof\u00f3bia deve ser evitada','A russia \u00e9 superior aos Estados Unidos por ser comunista ']\n",
    "\n",
    "\n",
    "# Preparar os dados para a previs\u00e3o\n",
    "input_encodings = tokenizer(\n",
    "    b, truncation=True, padding=True, max_length=512, return_tensors='pt'\n",
    ")\n",
    "input_dataset = torch.utils.data.TensorDataset(\n",
    "    input_encodings['input_ids'], input_encodings['attention_mask']\n",
    ")\n",
    "input_loader = torch.utils.data.DataLoader(\n",
    "    input_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True\n",
    ")\n",
    "\n",
    "predictions = predict(loaded_model, input_loader)\n",
    "\n",
    "for text, prediction in zip(b, predictions):\n",
    "    print(f'Texto: {text} - Previs\u00e3o: {prediction}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bJ4wl4O7xIZW"
   },
   "outputs": [],
   "source": [
    "def is_valid_string(text):\n",
    "        \"\"\"\n",
    "        Verifica se uma string \u00e9 v\u00e1lida, ou seja, n\u00e3o \u00e9 composta somente por espa\u00e7os em branco,\n",
    "        pontua\u00e7\u00f5es ou numerais.\n",
    "\n",
    "        :param string: A string a ser verificada.\n",
    "        :type string: str\n",
    "        :return: Retorna True se a string \u00e9 v\u00e1lida e False caso contr\u00e1rio.\n",
    "        :rtype: bool\n",
    "        \"\"\"\n",
    "        if text.strip() and not all(char.isdigit() or char.isspace() or char in string.punctuation for char in text):\n",
    "            return True\n",
    "        return False\n",
    "class TokenCRIA():\n",
    "    \"\"\"\n",
    "    Classe para padronizar o acesso a informa\u00e7\u00f5es de tokens no formato CRIA\n",
    "\n",
    "    Atributos:\n",
    "    ----------\n",
    "        texto : str\n",
    "            Texto para compor Token\n",
    "        span : tuple\n",
    "            Tupla contendo posi\u00e7\u00e3o inicial e final do texto na string original\n",
    "    \"\"\"\n",
    "    def __init__(self, palavra, span):\n",
    "        self.text = str(palavra)\n",
    "        self.start = int(span[0])\n",
    "        self.end = int(span[1])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.text\n",
    "\n",
    " \n",
    "\n",
    "def divideSentencas(texto):\n",
    "        \"\"\"\n",
    "        Divide as senten\u00e7as de um texto.\n",
    "        ...\n",
    "\n",
    "        Atributos:\n",
    "        ---------\n",
    "            texto : str\n",
    "                String a ser dividida\n",
    "\n",
    "        Retorna:\n",
    "        ---------\n",
    "                list[TokenCRIA] : list\n",
    "                    Lista de TokenCRIA com senten\u00e7as do texto.\n",
    "        \"\"\"\n",
    "        sentence_separator = '.?!'\n",
    "        lista_expressoes_abreviadas = [\n",
    "            r'\\d',r'Art',r'Lei',r'N',r'Dr',r'Dra',\n",
    "            r'Sr',r'Sra',r'Av',r'Sec',r'Apt']\n",
    "        negative_lookbehind = '?<!'\n",
    "        regular_exceptions = ''.join([f'({negative_lookbehind}{expressao})' for expressao in lista_expressoes_abreviadas])\n",
    "        sentence_endings_pattern = f\"{regular_exceptions}([{sentence_separator}])\"\n",
    "        splitStep = re.split(sentence_endings_pattern, texto)\n",
    "        splitedList = [splitStep[index]+splitStep[index+1] for index in range(0,len(splitStep),2) if index!= len(splitStep)-1]\n",
    "        sentences = [sentenca for sentenca in splitedList if is_valid_string(sentenca)]\n",
    "        pos_finais = [texto.index(sentenca) + len(sentenca) for sentenca in sentences]\n",
    "        pos_iniciais = [texto.index(sentenca) for sentenca in sentences]\n",
    "        \n",
    "        return [TokenCRIA(sentenca, (pos_iniciais[i], pos_finais[i])) for i, sentenca in enumerate(sentences)]\n",
    "a = divideSentencas('ontem eu estava andando quando derepente fui pego de surpresa! havia um sapo atraz de mim.')\n",
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "tk1DVDcmywW8"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
